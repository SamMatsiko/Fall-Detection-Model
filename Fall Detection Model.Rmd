---
title: "Fall Detection Model"
author: "Samuel Matsiko"
date: "12/29/2019"
output: pdf_document
---



```{r,include=FALSE}
if(!require(ggcorrplot)) install.packages("ggcorrplot", repos = "http://cran.us.r-project.org")
if(!require(dplyr)) install.packages("dplyr", repos = "http://cran.us.r-project.org")
if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(randomForest)) install.packages("randomForest", repos = "http://cran.us.r-project.org")
if(!require(e1071)) install.packages("e1071", repos = "http://cran.us.r-project.org")
if(!require(readr)) install.packages("readr", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")
```

# Introduction

The dataset was obtained from Kaggle(https://www.kaggle.com/pitasr/falldata). As detailed on the website, this dataset was generated by wearable motion sensor units fit to the subjectsâ€™ body at six different positions. Each unit comprises of three tri-axial devices (accelerometer, gyroscope, and magnetometer/compass). Fourteen volunteers performed a standardized set of movements including 20 voluntary falls and 16 activities of daily living (ADLs), resulting in a large dataset with 16382 trials. The dataset comprises of 7 variables, namely; ACTIVITY,TIME, SL, EEG, BP, HR and CIRCULATION. Find details on each column.

ACTIVITY - activity classification
TIME - monitoring time
SL - sugar level
EEG - EEG monitoring rate
BP - Blood pressure
HR - Heart beat rate
CIRCLUATION - Blood circulation

The aim is to build a model that detects falls for people in the fall risk groups. With this dataset, i have built a model using 6 predictors to differentiate 6 human movements(captured under the target label variable, ACTIVITY) of Standing, Walking, Sitting, Falling, Cramps and Running that are represented by values of 0,1,2,3,4,5 repectively. 

As indicated in the method section below, the data has first been explored using the different technicques that have guided on the machine learning approaches to deploy. Three machine learning algorithms have been considered and the final testing coducted with the best performing algorithm, random forest. 




# Method

Using different exploratory techniques detailed below, data is observed to be in tidy format with no null values. However, data has been observed to be of varying scales and has therfore been scaled. Further more, predictors are not correlated to the target label. It is also important to note that the variables are generally non-uniformly distributed. Given this nature of data, svm,knn and random forest machine learning approaches have been deployed 


```{r FallData, include=FALSE}
urlfile="https://raw.githubusercontent.com/SamMatsiko/Fall-Detection-Model/master/falldeteciton.csv
"
FallData<-read_csv(url(urlfile))
FallData<-as.data.frame(FallData)
FallData$ACTIVITY<-as.factor(FallData$ACTIVITY)
```
## Data Overview
**Dimensions of the dataset**
```{r, echo=FALSE}
dim(FallData)
```
**Column names of the dataset**
```{r,echo=FALSE}
colnames(FallData)
```
**Data Types of the dataset**
```{r echo=FALSE}
sapply(FallData,class) 
```
**Layout of the dataset**
```{r ,echo=FALSE}

head(FallData)
```
**Checking for null values**
```{r }
any(is.na(FallData))
```

**Summary of the dataset**

```{r ,echo=FALSE}
summary(FallData)

```
Seeing the different variables are of have varying scales(from above), all predictors have been scaled but not the target label variable, ACTIVITY. We also observe that the target label values are imbalanced as indicated below in percentage proportions. 
```{r ,echo=FALSE}
FallData[,2:7]<-scale(FallData[,2:7])
```
**Summary after scaling**
```{r ,echo=FALSE}
summary(FallData)
```
**Target label proportion**
```{r echo=FALSE}
percentage <- prop.table(table(FallData$ACTIVITY)) * 100
cbind(Count=table(FallData$ACTIVITY), Percentage=round(percentage,2))
```

## Understanding Correlation between Variables
From the correlation matrix below and the corresponding plot, data is largely not correlated. Hence, SVM,KNN and random forests approaches have been considered in modelling the data.

**Correlation matrix**
```{r,echo=FALSE}
FallData$ACTIVITY<-as.numeric(FallData$ACTIVITY)
correlationMatrix<-round(cor(FallData),1) 
correlationMatrix

```

**A plot of the correlation matrix**

```{r , echo=FALSE}
ggcorrplot(correlationMatrix)
```


## Distribution of Data

Exploring distribution of data by boxplot and histograms for each variable, and distribution of each variable for every target label, data is seen to be non-randomly distributed, even after scaling. 

**Boxplots of individuals variables**

```{r ,echo=FALSE}
par(mfrow=c(1,6))
  for(i in 1:6) {
  boxplot(FallData[,2:7][,i], main=colnames(FallData)[i])
}
```
```{r,echo=FALSE}
par(mfrow=c(1,3))
  for(i in 1:3) {
  hist(FallData[,2:7][,i], main=colnames(FallData)[i])
}
```
```{r,echo=FALSE}
par(mfrow=c(1,3))
  for(i in 4:6) {
  hist(FallData[,2:7][,i], main=colnames(FallData)[i])
}
```
```{r echo=FALSE}
hist(FallData$CIRCLUATION,main=colnames(FallData$CIRCLUATION))
```
**Distribution of target variables against each predictor**

```{r,echo=FALSE}
FallData$ACTIVITY<-as.factor(FallData$ACTIVITY)
FallData %>% gather(Metric, Value, -ACTIVITY) %>%
  ggplot(aes(ACTIVITY, Value, fill = ACTIVITY)) +
  geom_boxplot() +
  facet_wrap(~Metric, scales = "free") +
  theme(axis.text.x = element_blank())
```

## Modelling methodology

Given the correlation and distribution of data, Support Vector Machines(SVM),knn and random forest machine learnining algorithms have been considered.The dataset is first split into main and validation sets in ratios of 8:2 respectively. While the validation set has been set aside for final tests, the main set has been split further into train and test sets in proportions of 50% each for intermidiate training and testing to determine the best performing approach. 

The three machine learning algorithms have been deployed to train(with train set) and test(with test set) to determine the best performing algorithm. The best performing algorithm is the random forest approach that has been trained with the main set and tested with the validation set to obtain an accuracy of 77%. Accuracy is the preffered preformance metric as the model is expected to distinguish the different human movements. 


# Results

The table below shows results by the different machine learning approaches. Training and testing is first done on train set and test set respectively to determine the best performing algorithm. Lastly, since random forest is the best performing algorithm, it has been trained(with the main set) and tested(with the validation set) to obtain an accuracy of 77%.

```{r,echo=FALSE}
Partition_set <- createDataPartition(y = FallData$ACTIVITY , times = 1,p = 0.2, list = FALSE)
main_set <- FallData[-Partition_set,]
validation_set <- FallData[Partition_set,]

#Subpartitioning the remaining set into train and test sets 
test_index <- createDataPartition(y = main_set$ACTIVITY, times = 1,p = 0.5, list = FALSE)
train_set <- main_set[-test_index,]
test_set <- main_set[test_index,]

#Training with svm on train_Set and tests on test_set
svm_fit <- svm(ACTIVITY ~ . ,train_set)
y_hat_svm <- predict(svm_fit, test_set)
cm_svm<-confusionMatrix(y_hat_svm,test_set$ACTIVITY)$overall["Accuracy"]

#Creating a table that will store accuracy results of each ML algorithm
Accuracy_results <- tibble(Method = "Training with Svm",  Accuracy= cm_svm)



#Training with knn on train_Set and tests on test_set
knn_fit<-train(ACTIVITY~.,data = train_set,method="knn")
y_hat_knn<-predict(knn_fit,test_set)
cm_knn<-confusionMatrix(y_hat_knn,test_set$ACTIVITY)$overall["Accuracy"]
Accuracy_results <- bind_rows(Accuracy_results,
                              tibble(Method="Training with knn",
                                     Accuracy = cm_knn))


#Training with random forest on train_Set and tests on test_set

rf_fit <- randomForest(ACTIVITY~., data = train_set)

y_hat_rf<-predict(rf_fit,test_set)

cm_rf<-confusionMatrix(y_hat_rf,test_set$ACTIVITY)$overall["Accuracy"]
Accuracy_results <- bind_rows(Accuracy_results,
                              tibble(Method="Training with random forest",
                                     Accuracy = cm_rf))



#Final test on validation set using random forest

rf_fit_main <- randomForest(ACTIVITY~ ., data = main_set)

y_hat_rf_main<-predict(rf_fit_main,validation_set)

cm_rf_main<-confusionMatrix(y_hat_rf_main,validation_set$ACTIVITY)$overall["Accuracy"]
Accuracy_results <- bind_rows(Accuracy_results,
                              tibble(Method="Final test on Random forest with validation set",
                                     Accuracy = cm_rf_main))
as.data.frame(Accuracy_results) 

```
**Determining imporatance of predictors**

The importance of predictors is detailed in the table below.

```{r echo=FALSE}
importance(rf_fit_main)
```




# Conclusion
A fall detection system to detect falls from five other human movements has been built using a random forest machine learning approach with an overall accuracy of 77%. While the accuracy is still wanting, performance of the model can improved with more data as already observed in the difference of accuracy when training with less and much more data. Performance of the model might also be improved if trained with real-world scenarios data. Future works will look at feature engineering, ensembling and PCA in a bid to improve performance.  








