---
title: "Fall Detection Model"
author: "Samuel Matsiko"
date: "12/29/2019"
output: pdf_document
---



```{r,include=FALSE}
if(!require(ggcorrplot)) install.packages("ggcorrplot", repos = "http://cran.us.r-project.org")
if(!require(dplyr)) install.packages("dplyr", repos = "http://cran.us.r-project.org")
if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
```

# Introduction

The dataset was obtained from Kaggle(https://www.kaggle.com/pitasr/falldata). As detailed on the website, this dataset was generated by wearable motion sensor units fit to the subjectsâ€™ body at six different positions. Each unit comprises of three tri-axial devices (accelerometer, gyroscope, and magnetometer/compass). Fourteen volunteers performed a standardized set of movements including 20 voluntary falls and 16 activities of daily living (ADLs), resulting in a large dataset with 16382 trials. The dataset comprises of 7 variables, namely; ACTIVITY,TIME, SL, EEG, BP, HR and CIRCULATION. Find details on each column.

ACTIVITY - activity classification
TIME - monitoring time
SL - sugar level
EEG - EEG monitoring rate
BP - Blood pressure
HR - Heart beat rate
CIRCLUATION - Blood circulation

The aim is to build a model that detects falls for people in the fall risk groups. With this dataset, i have built a model using 6 predictors to differentiate 6 human movements(captured under the target label variable, ACTIVITY) of Standing, Walking, Sitting, Falling, Cramps and Running that are represented by values of 0,1,2,3,4,5 repectively. 

As indicated in the method section below, the data has first been explored using the different technicques that have guided on the machine learning approaches to deploy. 




# Method

Using different exploratory techniques detailed below, data is observed to be in tidy format with no null values. However, data has been observed to be of varying scales and has therfore been scaled. Further more, predictors are not correlated to the target label. It is also important to note that the variables are generally non-uniformly distributed. Given this nature of data, svm,knn and random forest machine learning approaches have been deployed 


```{r FallData, echo=FALSE}
FallData =read.csv("falldeteciton.csv")
FallData$ACTIVITY<-as.factor(FallData$ACTIVITY)
```
## Data Overview
**Dimensions of the dataset**
```{r, echo=FALSE}
dim(FallData)
```
**Column names of the dataset**
```{r,echo=FALSE}
colnames(FallData)
```
**Data Types of the dataset**
```{r echo=FALSE}
sapply(FallData,class) 
```
**Layout of the dataset**
```{r ,echo=FALSE}

head(FallData)
```
**Checking for null values**
```{r ,echo=FALSE}
any(is.na(FallData))
```

**Summary of the dataset**

```{r ,echo=FALSE}
summary(FallData)

```
Seeing the different variables are of have varying scales(from above), all predictors have been scaled but not the target label variable, ACTIVITY. We also observe that the target label values are imbalanced as indicated below in percentage proportions. 
```{r ,echo=FALSE}
FallData[,2:7]<-scale(FallData[,2:7])
```
**Summary after scaling**
```{r ,echo=FALSE}
summary(FallData)
```
**Target label proportion**
```{r echo=FALSE}
percentage <- prop.table(table(FallData$ACTIVITY)) * 100
cbind(Count=table(FallData$ACTIVITY), Percentage=round(percentage,2))
```

## Understanding Correlation between Variables
From the correlation matrix below and the corresponding plot, data is largely not correlated. Hence, SVM,KNN and random forests approaches have been considered in modelling the data.

**Correlation matrix**
```{r,echo=FALSE}
FallData$ACTIVITY<-as.numeric(FallData$ACTIVITY)
correlationMatrix<-round(cor(FallData),1) 
correlationMatrix

```

**A plot of the correlation matrix**

```{r , echo=FALSE}
ggcorrplot(correlationMatrix)
```


## Distribution of Data

Exploring distribution of data by boxplot and histograms for each variable, and distribution of each variable for every target label, data is seen to be non-randomly distributed, even after scaling. 

**Boxplots of individuals variables**

```{r ,echo=FALSE}
par(mfrow=c(1,6))
  for(i in 1:6) {
  boxplot(FallData[,2:7][,i], main=colnames(FallData)[i])
}
```
```{r,echo=FALSE}
par(mfrow=c(1,3))
  for(i in 1:3) {
  hist(FallData[,2:7][,i], main=colnames(FallData)[i])
}
```
```{r,echo=FALSE}
par(mfrow=c(1,3))
  for(i in 4:6) {
  hist(FallData[,2:7][,i], main=colnames(FallData)[i])
}
```
```{r echo=FALSE}
hist(FallData$CIRCLUATION,main=colnames(FallData$CIRCLUATION))
```
**Distribution of target variables against each predictor**

```{r,echo=FALSE}
FallData$ACTIVITY<-as.factor(FallData$ACTIVITY)
FallData %>% gather(Metric, Value, -ACTIVITY) %>%
  ggplot(aes(ACTIVITY, Value, fill = ACTIVITY)) +
  geom_boxplot() +
  facet_wrap(~Metric, scales = "free") +
  theme(axis.text.x = element_blank())
```


## Results
The model has been trained with three machine learning approaches, Support Vector Machines(SVM),knn and random forest as the data is largely not correlated and non-uniformally distributed. For a model that distinguishes different human movements, the performance metric chosen is accuracy.Random forest produced the best results with accuracy at 77% for the final results and Sensitivity of 75% and Specificity of 89% for class 3, the falling category. During training, SVM had the lowest accuracy at 23% followed by knn at 59% and random forest had 75%.

## Conclusion
A fall detection system to detect falls from six other human movements has been built using a random forest machine learning approach with an overall accuracy of 77%. While the accuracy is still wanting, performance of the model can improved with more data as already observed in the accuracy difference when training with less and much more data. Performance of the model might also be improved if trained with real-world scenarios data. Future works will look at feature engineering, ensembling and PCA in a bid to improve performance.  








